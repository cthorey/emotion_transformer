{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from ipywidgets import interact\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "> data exploration and construction of the Dataloader for the SemEval-2019 Task 3 dataset (contextual emotion detection in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "Let us first take a look at the data using Pandas. Note that we use the [preprocessed, cleaned data from PhilippMaxx](https://github.com/PhilippMaxx/SemEval2019Task3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def open_data(path):\n",
    "    \"\"\"\n",
    "    returns a Pandas DataFrame consisting of the SemEval data at path `path`  \n",
    "    \"\"\"\n",
    "    return pd.read_csv(path, delimiter='\\t', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not worry i am girl</td>\n",
       "      <td>hmm how do i know if you are</td>\n",
       "      <td>what ' s ur name ?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when did i ?</td>\n",
       "      <td>saw many times i think shame</td>\n",
       "      <td>no . i never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>by</td>\n",
       "      <td>by google chrome</td>\n",
       "      <td>where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u r ridiculous</td>\n",
       "      <td>i might be ridiculous but i am telling the tru...</td>\n",
       "      <td>u little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     turn1                                              turn2  \\\n",
       "id                                                                              \n",
       "0   do not worry i am girl                       hmm how do i know if you are   \n",
       "1             when did i ?                       saw many times i think shame   \n",
       "2                       by                                   by google chrome   \n",
       "3           u r ridiculous  i might be ridiculous but i am telling the tru...   \n",
       "4       just for time pass                         wt do u do 4 a living then   \n",
       "\n",
       "                        turn3   label  \n",
       "id                                     \n",
       "0          what ' s ur name ?  others  \n",
       "1        no . i never saw you   angry  \n",
       "2              where you live  others  \n",
       "3   u little disgusting whore   angry  \n",
       "4                       maybe  others  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/clean_train.txt'\n",
    "df = open_data(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30160, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we are dealing with very unformal language, typos, and bad grammar. Moreoever, we are given an unbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others    14948\n",
       "angry      5506\n",
       "sad        5463\n",
       "happy      4243\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms\n",
    "\n",
    "We now tokenize the examples into features and create attention masks according to the (Distil)Bert standard. The following image from Jay Alammar's great blog post [A Visual Guide to Using BERT for the First Time](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/) visualizes the tokenization step.\n",
    "\n",
    "![Tokenization explained visually](./images/bert-distilbert-tokenization-2-token-ids.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def transform_data(df, max_seq_len):\n",
    "    \"\"\"\n",
    "    returns the padded input ids and attention masks according to the DistilBert tokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    def tokenize_fct(turn):\n",
    "        return tokenizer.encode(turn, add_special_tokens=True, max_length=max_seq_len)\n",
    "    \n",
    "    tokenized = df[['turn1','turn2','turn3']].applymap(tokenize_fct)\n",
    "    padded = torch.tensor([[ids + [0]*(max_seq_len-len(ids)) for ids in idx] for idx in tokenized.values])\n",
    "    attention_mask = torch.where(padded != 0, torch.ones_like(padded), torch.zeros_like(padded))\n",
    "    return padded, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 10\n",
    "padded, attention_mask = transform_data(df, max_seq_len)\n",
    "assert padded.shape == attention_mask.shape == df[['turn1','turn2','turn3']].shape + (max_seq_len,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets digest the outcome for the first two conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not worry i am girl</td>\n",
       "      <td>hmm how do i know if you are</td>\n",
       "      <td>what ' s ur name ?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when did i ?</td>\n",
       "      <td>saw many times i think shame</td>\n",
       "      <td>no . i never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     turn1                         turn2  \\\n",
       "id                                                         \n",
       "0   do not worry i am girl  hmm how do i know if you are   \n",
       "1             when did i ?  saw many times i think shame   \n",
       "\n",
       "                   turn3   label  \n",
       "id                                \n",
       "0     what ' s ur name ?  others  \n",
       "1   no . i never saw you   angry  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utterances are transformed according to the tokenizer vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['[CLS]', '101', 'do', '2079', 'not', '2025', 'worry', '4737',\n",
       "         'i', '1045', 'am', '2572', 'girl', '2611', '[SEP]', '102',\n",
       "         '[PAD]', '0', '[PAD]', '0'],\n",
       "        ['[CLS]', '101', 'hmm', '17012', 'how', '2129', 'do', '2079',\n",
       "         'i', '1045', 'know', '2113', 'if', '2065', 'you', '2017',\n",
       "         'are', '2024', '[SEP]', '102'],\n",
       "        ['[CLS]', '101', 'what', '2054', \"'\", '1005', 's', '1055', 'ur',\n",
       "         '24471', 'name', '2171', '?', '1029', '[SEP]', '102', '[PAD]',\n",
       "         '0', '[PAD]', '0']],\n",
       "\n",
       "       [['[CLS]', '101', 'when', '2043', 'did', '2106', 'i', '1045',\n",
       "         '?', '1029', '[SEP]', '102', '[PAD]', '0', '[PAD]', '0',\n",
       "         '[PAD]', '0', '[PAD]', '0'],\n",
       "        ['[CLS]', '101', 'saw', '2387', 'many', '2116', 'times', '2335',\n",
       "         'i', '1045', 'think', '2228', 'shame', '9467', '[SEP]', '102',\n",
       "         '[PAD]', '0', '[PAD]', '0'],\n",
       "        ['[CLS]', '101', 'no', '2053', '.', '1012', 'i', '1045',\n",
       "         'never', '2196', 'saw', '2387', 'you', '2017', '[SEP]', '102',\n",
       "         '[PAD]', '0', '[PAD]', '0']]], dtype='<U18')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(list(DistilBertTokenizer.from_pretrained('distilbert-base-uncased').vocab.items()))\n",
    "vocab[padded[:2]].reshape(2,3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...resulting in the corresponding input ids (padded with zeros to `max_seq_len`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  101,  2079,  2025,  4737,  1045,  2572,  2611,   102,     0,     0],\n",
       "         [  101, 17012,  2129,  2079,  1045,  2113,  2065,  2017,  2024,   102],\n",
       "         [  101,  2054,  1005,  1055, 24471,  2171,  1029,   102,     0,     0]],\n",
       "\n",
       "        [[  101,  2043,  2106,  1045,  1029,   102,     0,     0,     0,     0],\n",
       "         [  101,  2387,  2116,  2335,  1045,  2228,  9467,   102,     0,     0],\n",
       "         [  101,  2053,  1012,  1045,  2196,  2387,  2017,   102,     0,     0]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and masks for the self-attention layers specifying the length of each utterance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also transform the labels to integers according to a given dictionary `emo_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def get_labels(df, emo_dict):\n",
    "    \"\"\"\n",
    "    returns the labels according to the emotion dictionary\n",
    "    \"\"\"\n",
    "    return torch.tensor([emo_dict[label] for label in df['label'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_dict = {'others': 0, 'sad': 1, 'angry': 2, 'happy': 3}\n",
    "labels = get_labels(df, emo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the result for our two conversations from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following widget allows to interactively explore the former data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba3771ccf824e4a9cbbb136a578dd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='idx', max=5), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "def print_features(idx):\n",
    "  input_ids = padded[idx,:].numpy()\n",
    "  print('original Data:', df.values[idx,:3].reshape(-1,1),         \n",
    "        'vocabulary:', vocab[input_ids].reshape(1,3,-1),\n",
    "        'padded input ids:', input_ids,\n",
    "        'attention mask:', attention_mask[idx,:].numpy(),\n",
    "        'original label:', df.values[idx,3],\n",
    "        'transformed label:', labels[idx].numpy(), sep = '\\n\\n')\n",
    "\n",
    "interact(print_features, idx = (0,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataloader\n",
    "\n",
    "Finally we aggregate all the functions above into a PyTorch dataloader (with optional [distributed training](https://pytorch.org/tutorials/beginner/aws_distributed_training_tutorial.html?highlight=distributedsampler))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def dataloader(path, max_seq_len, batch_size, emo_dict, use_ddp = False, labels = True):\n",
    "    \"\"\"\n",
    "    Transforms the .csv data stored in `path` according to DistilBert features and returns it as a DataLoader \n",
    "    \"\"\"\n",
    "    df = open_data(path)\n",
    "    padded, attention_mask = transform_data(df, max_seq_len)\n",
    "    \n",
    "    if labels:\n",
    "        dataset = TensorDataset(padded, attention_mask, get_labels(df, emo_dict))\n",
    "    \n",
    "    else:\n",
    "        dataset = TensorDataset(padded, attention_mask)\n",
    "        \n",
    "    if use_ddp:\n",
    "        train_sampler = DistributedSampler(dataset)\n",
    "    \n",
    "    else: \n",
    "        train_sampler = None\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=(train_sampler is None), \n",
    "                      sampler=train_sampler, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "loader = dataloader(path, max_seq_len, batch_size, emo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch consists of `batch_size` input ids, attention_masks, and optionally the corresponding labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[  101,  1045,  2572,  2643,   102,     0,     0,     0,     0,     0],\n",
       "          [  101,  2025,  2074,  2023,  5304,  1012,  2017,  2024,  4242,   102],\n",
       "          [  101,  2025,  2428,   102,     0,     0,     0,     0,     0,     0]],\n",
       " \n",
       "         [[  101,  2748,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  1030,  2068,   102,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2425,  2033,  2242,  2008,  2097,  3037,  2033,  1012,   102]],\n",
       " \n",
       "         [[  101,  2821,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  1997, 17876,  5262,   999,  7653,  2227,   102,     0,     0],\n",
       "          [  101,  2024,  2017,  2183,  2000,  3637,   102,     0,     0,     0]],\n",
       " \n",
       "         [[  101,  2079,  2025,  2131,  2046,  1996,  4751,   102,     0,     0],\n",
       "          [  101,  2023,  2003,  5024,  6040,  1012,   102,     0,     0,     0],\n",
       "          [  101,  2748,  1045,  2064,  2025,  5454,   102,     0,     0,     0]],\n",
       " \n",
       "         [[  101,  1045,  2031,  2070,  2147,  2000,  2079,   102,     0,     0],\n",
       "          [  101,  2168,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  2061,  2175,  2079,  2115,  2147,   102,     0,     0,     0]]]),\n",
       " tensor([[[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "          [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]]),\n",
       " tensor([0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find, for instance, the first conversation of this batch in our input ids above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = batch[0][0]\n",
    "assert torch.any(torch.all(torch.all(conversation == padded, dim=2), dim=1)) == True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
