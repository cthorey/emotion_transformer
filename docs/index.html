---

title: Contextual Emotion Detection in Text (DoubleDistilBert Model)

keywords: fastai
sidebar: home_sidebar

summary: "We use the excellent pytorch-lightning, Huggingface transformers, and fast.ai nbdev libraries for a clean and efficient implementation and demonstrate the performance of our model on the SemEval-2019 Task 3 dataset."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/DoubleDistilBert_Lightning.png" alt="Project Image"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://www.aclweb.org/anthology/S19-2005/">SemEval-2019 Task 3 description</a>: </p>
<p>"Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading "Why don't you ever text me!" we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps."</p>
<p><strong>Approach:</strong> Pre-Trained DistilBert <code>transformers</code> model for sentence embeddings and contextual information via another Bert model on top</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Install">Install<a class="anchor-link" href="#Install">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pip install packaging</code></p>
<p><code>pip install git+https://github.com/juliusberner/emotion_transformer</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="How-To-Use">How To Use<a class="anchor-link" href="#How-To-Use">&#182;</a></h3><ol>
<li><p>Training and testing the default configuration (e.g. on GPU with index 0)</p>
<p><code>python main.py --mode=test --gpus='0'</code></p>
</li>
</ol>
<ol>
<li><p>Parallel hyperparameter search on 8 GPUs using half-precision (automatically done by <code>test_tube</code> and <code>pytorch_lightning</code>):</p>
<p><code>python main.py --mode=hparams_search --gpus='0 1 2 3 4 5 6 7' --use_16bit</code></p>
</li>
</ol>
<p>alternativ: Parallel hyperparameter search on 8 GPUs (2 GPUs with with specified indices for each setting):</p>
<p><code>python main.py --mode=hparams_search --gpus='0,1 2,3 4,5 6,7' --distributed_backend='dp'</code></p>
<p>(tested with nvidia-docker <code>FROM nvcr.io/nvidia/pytorch:19.02-py3</code> as specified in <code>requirements.txt</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Documentation">Documentation<a class="anchor-link" href="#Documentation">&#182;</a></h3><p>automatically created by <code>nbdev</code>: <a href="https://juliusberner.github.io/emotion_detect/">Documentation</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Notebooks">Notebooks<a class="anchor-link" href="#Notebooks">&#182;</a></h3><p>Jupyter notebooks explaining the dataloader, the model, and the lightning module:</p>
<p><code>00_dataloader.ipynb</code></p>
<p><code>01_model.ipynb</code></p>
<p><code>02_lightning.ipynb</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Featuring">Featuring<a class="anchor-link" href="#Featuring">&#182;</a></h3><ul>
<li><a href="https://github.com/williamFalcon/pytorch-lightning/">PyTorch Lightning</a>: "Lightning is a very lightweight wrapper on PyTorch that decouples the science code from the engineering code. It's more of a style-guide than a framework. By refactoring your code, we can automate most of the non-research code."</li>
</ul>
<p><img src="images/pl.gif" alt="Lightning Describtion"></p>
<ul>
<li><a href="https://github.com/huggingface/transformers">Huggingface transformers</a>: "Transformers provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch."</li>
</ul>
<p><img src="images/transformers_logo_name.png" alt="transformers logo"></p>
<ul>
<li><p><a href="https://github.com/fastai/nbdev">fast.ai nbdev</a>: "nbdev is a library that allows you to fully develop a library in Jupyter Notebooks, putting all your code, tests and documentation in one place."</p>
</li>
<li><p><a href="https://github.com/williamFalcon/test-tube">William Falcon's test tube</a> "Test tube is a python library to track and parallelize hyperparameter search for Deep Learning and ML experiments. It's framework agnostic and built on top of the python argparse API for ease of use."</p>
</li>
</ul>
<p><img src="images/test_tube_logo.png" alt="test tube logo"></p>

</div>
</div>
</div>
</div>
 

